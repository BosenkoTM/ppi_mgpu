# -*- coding: utf-8 -*-
"""PPI_Dataset_Formation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1...
"""

# ==============================================================================
#  –®–∞–≥ 1: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫
# ==============================================================================
print("‚è≥ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫...")
!pip install moviepy opencv-python-headless pandas openpyxl transformers torch -q
!pip install git+https://github.com/openai/whisper.git -q
!pip install huggingface_hub -q
print("‚úÖ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")

import os
import json
import pandas as pd
import cv2
from moviepy.editor import VideoFileClip
import whisper
import torch
from IPython.display import display, Image, Video, HTML
from google.colab import drive
from huggingface_hub import notebook_login, create_repo, upload_folder

# –ú–æ–Ω—Ç–∏—Ä—É–µ–º Google Drive –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ —Ñ–∞–π–ª–∞–º
print("üîë –ú–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Google Drive...")
drive.mount('/content/drive')
print("‚úÖ Google Drive —Å–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω.")

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ GPU (Whisper –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –±—ã—Å—Ç—Ä–µ–µ)
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(f"üöÄ –í—ã–±—Ä–∞–Ω–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π: {DEVICE}")


# ==============================================================================
#  –®–∞–≥ 2: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—É—Ç–µ–π –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
# ==============================================================================
# –£–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ –≤–∞—à–∏–º —Ñ–∞–π–ª–∞–º –Ω–∞ Google Drive
DRIVE_PATH = '/content/drive/MyDrive/PPI_Project/' # <-- –ò–ó–ú–ï–ù–ò–¢–ï –ù–ê –í–ê–® –ü–£–¢–¨

# –í—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã
VIDEO_INPUT_PATH = os.path.join(DRIVE_PATH, '03.mp4')
JSON_INPUT_PATH = os.path.join(DRIVE_PATH, '03.json')
PATTERNS_XLSX_PATH = os.path.join(DRIVE_PATH, 'patterns.xlsx')

# –í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞
DATASET_OUTPUT_DIR = '/content/ppi_final_dataset'
os.makedirs(DATASET_OUTPUT_DIR, exist_ok=True)

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ñ–∞–π–ª–æ–≤
for path in [VIDEO_INPUT_PATH, JSON_INPUT_PATH, PATTERNS_XLSX_PATH]:
    if not os.path.exists(path):
        raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏: {path}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –ø—É—Ç–∏ –≤ DRIVE_PATH.")
print("‚úÖ –í—Å–µ –≤—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã –Ω–∞–π–¥–µ–Ω—ã.")

# –ó–∞–≥—Ä—É–∑–∫–∞ –æ–ø–∏—Å–∞–Ω–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
patterns_df = pd.read_excel(PATTERNS_XLSX_PATH)
patterns_dict = {row['pattern type']: row['comments'] for index, row in patterns_df.iterrows()}
print("üìò –û–ø–∏—Å–∞–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω—ã:")
display(patterns_df)


# ==============================================================================
#  –®–∞–≥ 3: –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ –∏ JSON
# ==============================================================================

# –°–∂–∞—Ç–∏–µ –≤–∏–¥–µ–æ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
COMPRESSED_VIDEO_PATH = '/content/03_compressed.mp4'
print(f"‚è≥ –°–∂–∞—Ç–∏–µ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞... (—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç)")
!ffmpeg -i "{VIDEO_INPUT_PATH}" -vcodec libx264 -crf 23 -y "{COMPRESSED_VIDEO_PATH}" -hide_banner -loglevel error
print(f"‚úÖ –í–∏–¥–µ–æ —Å–∂–∞—Ç–æ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {COMPRESSED_VIDEO_PATH}")


def parse_label_studio_json(json_path):
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏–∑ JSON Label Studio."""
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    parsed_patterns = []
    
    for task in data:
        for annotation in task.get('annotations', []):
            for result in annotation.get('result', []):
                result_type = result.get('type')
                value = result.get('value', {})
                
                if result_type == 'labels' and 'labels' in value:
                    pattern_name = value['labels'][0]
                    start_time = value['start']
                    end_time = value['end']
                    parsed_patterns.append({
                        "type": "audio",
                        "start": start_time,
                        "end": end_time,
                        "pattern": pattern_name
                    })
                elif result_type == 'videorectangle' and 'sequence' in value:
                    # –î–ª—è –≤–∏–¥–µ–æ-–ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–æ–≤ –±–µ—Ä–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è
                    sequence = value['sequence']
                    if not sequence: continue
                    
                    times = [item['time'] for item in sequence]
                    start_time = min(times)
                    end_time = max(times)
                    
                    # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –¥–ª—è videorectangle –Ω–µ—Ç —è–≤–Ω–æ–≥–æ –ª–µ–π–±–ª–∞ –≤ JSON,
                    # –∏ –µ–≥–æ –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç —Å–≤—è–∑–∞—Ç—å —Å –∞—É–¥–∏–æ-–¥–æ—Ä–æ–∂–∫–æ–π –∏–ª–∏ –∑–∞–¥–∞—Ç—å –≤—Ä—É—á–Ω—É—é.
                    # –í –¥–∞–Ω–Ω–æ–º –ø—Ä–∏–º–µ—Ä–µ –º—ã –µ–≥–æ –ø—Ä–æ–ø—É—Å—Ç–∏–º, –Ω–æ –ª–æ–≥–∏–∫–∞ —Ä–∞—Å—à–∏—Ä—è–µ–º–∞.
                    # print(f"–ù–∞–π–¥–µ–Ω –≤–∏–∑—É–∞–ª—å–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω: {start_time}-{end_time}")

    return parsed_patterns

print("\nüîç –ü–∞—Ä—Å–∏–Ω–≥ JSON —Ñ–∞–π–ª–∞ —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π...")
pattern_segments = parse_label_studio_json(JSON_INPUT_PATH)
print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(pattern_segments)} –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏.")
print("–ü—Ä–∏–º–µ—Ä –ø–µ—Ä–≤—ã—Ö 5 –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π:")
for p in pattern_segments[:5]:
    print(f"- {p['pattern']} ({p['start']:.2f}s - {p['end']:.2f}s)")


# ==============================================================================
#  –®–∞–≥ 4: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞
# ==============================================================================

# –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–¥–ø–∞–ø–æ–∫ –¥–ª—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
IMAGES_DIR = os.path.join(DATASET_OUTPUT_DIR, 'images')
VIDEOS_DIR = os.path.join(DATASET_OUTPUT_DIR, 'videos')
TEXTS_DIR = os.path.join(DATASET_OUTPUT_DIR, 'texts')
os.makedirs(IMAGES_DIR, exist_ok=True)
os.makedirs(VIDEOS_DIR, exist_ok=True)
os.makedirs(TEXTS_DIR, exist_ok=True)

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Whisper
print("\n‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Whisper... (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ)")
whisper_model = whisper.load_model("base", device=DEVICE)
print("‚úÖ –ú–æ–¥–µ–ª—å Whisper –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")

metadata = []
source_video_clip = VideoFileClip(COMPRESSED_VIDEO_PATH)

print("\nüöÄ –ù–∞—á–∞–ª–æ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω...")
for i, segment in enumerate(pattern_segments):
    pattern_id = f"pattern_{i}"
    start_time = segment['start']
    end_time = segment['end']
    pattern_type = segment['pattern']
    
    print(f"  -> –û–±—Ä–∞–±–æ—Ç–∫–∞ {pattern_id}: '{pattern_type}' [{start_time:.2f}s - {end_time:.2f}s]")

    # --- 1. –ù–∞—Ä–µ–∑–∫–∞ –≤–∏–¥–µ–æ—Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ ---
    clip_path = os.path.join(VIDEOS_DIR, f"{pattern_id}.mp4")
    try:
        subclip = source_video_clip.subclip(start_time, end_time)
        subclip.write_videofile(clip_path, codec="libx264", audio_codec="aac", logger=None)
    except Exception as e:
        print(f"    [!] –û—à–∏–±–∫–∞ –ø—Ä–∏ –Ω–∞—Ä–µ–∑–∫–µ –≤–∏–¥–µ–æ –¥–ª—è {pattern_id}: {e}")
        continue

    # --- 2. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤–æ–≥–æ –∫–∞–¥—Ä–∞ (–∏–∑ —Å–µ—Ä–µ–¥–∏–Ω—ã) ---
    frame_path = os.path.join(IMAGES_DIR, f"{pattern_id}.jpg")
    mid_time_sec = start_time + (end_time - start_time) / 2
    try:
        source_video_clip.save_frame(frame_path, t=mid_time_sec)
    except Exception as e:
        print(f"    [!] –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∫–∞–¥—Ä–∞ –¥–ª—è {pattern_id}: {e}")
        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º, –¥–∞–∂–µ –µ—Å–ª–∏ –∫–∞–¥—Ä –Ω–µ –∏–∑–≤–ª–µ—á–µ–Ω
        frame_path = None
        
    # --- 3. –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ ---
    text_path = os.path.join(TEXTS_DIR, f"{pattern_id}.txt")
    try:
        result = whisper_model.transcribe(clip_path, fp16=False if DEVICE == 'cpu' else True)
        transcribed_text = result['text'].strip()
        with open(text_path, 'w', encoding='utf-8') as f:
            f.write(transcribed_text)
    except Exception as e:
        print(f"    [!] –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –¥–ª—è {pattern_id}: {e}")
        transcribed_text = "" # –û—Å—Ç–∞–≤–ª—è–µ–º –ø—É—Å—Ç—ã–º –ø—Ä–∏ –æ—à–∏–±–∫–µ

    # --- 4. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö ---
    metadata.append({
        "id": pattern_id,
        "source_video": os.path.basename(VIDEO_INPUT_PATH),
        "start_time": round(start_time, 2),
        "end_time": round(end_time, 2),
        "pattern_type": pattern_type,
        "pattern_description": patterns_dict.get(pattern_type, "–û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"),
        "image_path": os.path.relpath(frame_path, DATASET_OUTPUT_DIR) if frame_path else None,
        "video_path": os.path.relpath(clip_path, DATASET_OUTPUT_DIR),
        "text_path": os.path.relpath(text_path, DATASET_OUTPUT_DIR)
    })

source_video_clip.close()
print("\n‚úÖ –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω.")


# ==============================================================================
#  –®–∞–≥ 5: –ü—Ä–æ—Å–º–æ—Ç—Ä –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
# ==============================================================================
def review_sample(index):
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ–¥–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞."""
    if index >= len(metadata):
        print(f"–ò–Ω–¥–µ–∫—Å {index} –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞. –î–æ—Å—Ç—É–ø–Ω–æ {len(metadata)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤.")
        return
        
    sample = metadata[index]
    
    print("="*50)
    print(f"–ü—Ä–æ—Å–º–æ—Ç—Ä —ç–ª–µ–º–µ–Ω—Ç–∞: {sample['id']}")
    print(f"–ü–∞—Ç—Ç–µ—Ä–Ω: {sample['pattern_type']}")
    print(f"–í—Ä–µ–º—è: {sample['start_time']}s - {sample['end_time']}s")
    print(f"–û–ø–∏—Å–∞–Ω–∏–µ: {sample['pattern_description']}")
    print("="*50)

    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞–¥—Ä–∞
    print("\nüñºÔ∏è –ö–ª—é—á–µ–≤–æ–π –∫–∞–¥—Ä:")
    image_full_path = os.path.join(DATASET_OUTPUT_DIR, sample['image_path'])
    if os.path.exists(image_full_path):
        display(Image(filename=image_full_path, width=400))
    else:
        print("–ö–∞–¥—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω.")

    # –í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –≤–∏–¥–µ–æ
    print("\nüé¨ –í–∏–¥–µ–æ—Ñ—Ä–∞–≥–º–µ–Ω—Ç:")
    video_full_path = os.path.join(DATASET_OUTPUT_DIR, sample['video_path'])
    if os.path.exists(video_full_path):
        display(Video(video_full_path, embed=True, width=400))
    else:
        print("–í–∏–¥–µ–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        
    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
    print("\nüìù –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:")
    text_full_path = os.path.join(DATASET_OUTPUT_DIR, sample['text_path'])
    if os.path.exists(text_full_path):
        with open(text_full_path, 'r', encoding='utf-8') as f:
            print(f.read())
    else:
        print("–¢–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω.")

# –ü—Ä–æ—Å–º–æ—Ç—Ä–∏–º —Å–ª—É—á–∞–π–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2-–π –ø–æ —Å—á–µ—Ç—É)
print("\nüî¨ –ü—Ä–æ—Å–º–æ—Ç—Ä –æ–¥–Ω–æ–≥–æ –∏–∑ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤...")
review_sample(2)


# ==============================================================================
#  –®–∞–≥ 6: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –≤ Hugging Face
# ==============================================================================
# –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ jsonl
metadata_path = os.path.join(DATASET_OUTPUT_DIR, 'metadata.jsonl')
with open(metadata_path, 'w', encoding='utf-8') as f:
    for item in metadata:
        f.write(json.dumps(item, ensure_ascii=False) + '\n')

print(f"\nüíæ –§–∏–Ω–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {DATASET_OUTPUT_DIR}")
print(f"üìÑ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª–µ: {metadata_path}")
print(f"\n–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –≥–æ—Ç–æ–≤–∞ –∫ –∑–∞–≥—Ä—É–∑–∫–µ –≤ Hugging Face.")

# --- –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –∑–∞–≥—Ä—É–∑–∫–µ –≤ Hugging Face ---
print("\n---")
print("‚òÅÔ∏è –ß—Ç–æ–±—ã –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç –≤ Hugging Face, –≤—ã–ø–æ–ª–Ω–∏—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ —è—á–µ–π–∫–∏:")

# –Ø—á–µ–π–∫–∞ 1: –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è
# notebook_login()

# –Ø—á–µ–π–∫–∞ 2: –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è –∏ –∑–∞–≥—Ä—É–∑–∫–∞
#
# HF_USERNAME = "your-username" # <-- –í–ê–® –õ–û–ì–ò–ù –ù–ê HUGGING FACE
# DATASET_NAME = "ppi-pedagogical-patterns-dataset" # <-- –ù–ê–ó–í–ê–ù–ò–ï –í–ê–®–ï–ì–û –î–ê–¢–ê–°–ï–¢–ê
#
# # –°–æ–∑–¥–∞–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–∞ Hugging Face
# repo_url = create_repo(
#     repo_id=f"{HF_USERNAME}/{DATASET_NAME}",
#     repo_type="dataset",
#     exist_ok=True
# )
# print(f"–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Å–æ–∑–¥–∞–Ω/–Ω–∞–π–¥–µ–Ω: {repo_url}")
#
# # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å—é –ø–∞–ø–∫—É —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º
# print("‚è≥ –ù–∞—á–∏–Ω–∞–µ—Ç—Å—è –∑–∞–≥—Ä—É–∑–∫–∞... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞.")
# upload_folder(
#     folder_path=DATASET_OUTPUT_DIR,
#     repo_id=f"{HF_USERNAME}/{DATASET_NAME}",
#     repo_type="dataset"
# )
# print("‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")