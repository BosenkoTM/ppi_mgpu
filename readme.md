# Датасет педагогических паттернов


Этот репозиторий содержит полный цикл инструментов для анализа видеоматериалов (например, уроков или интервью): от подготовки сырого видео до создания высококачественных датасетов и обучения моделей машинного обучения.

## Видение проекта

Проект разделен на четыре логические части, которые последовательно решают задачу извлечения знаний из видео:

1.  **Подготовка данных.** Автоматизация рутинной нарезки видео и извлечения мультимодальных данных (аудио, видео, текст) для экспертной разметки.
2.  **Экспертная разметка.** Использование платформы Label Studio для ручной аннотации данных экспертами.
3.  **Создание эталонного датасета.** Преобразование результатов разметки в профессиональный, документированный датасет изображений и его публикация на Hugging Face.
4.  **Автоматизация анализа.** Обучение и применение моделей машинного обучения для автоматического поиска паттернов в новых, неразмеченных видео.

### Архитектура и поток данных

```
[Исходное видео.mp4]
         |
         v
+--------------------------------+
| ЧАСТЬ 1: prepare_data.py       |
| (Быстрая нарезка, извлечение   |
| аудио/кадров/текста/признаков) |
+--------------------------------+
         |
         v
[processed_data/], [tasks.json]
         |
         v
+--------------------------------+
| ЧАСТЬ 2: Label Studio          |
| (Ручная разметка экспертами)   |
+--------------------------------+
         |
         v
[labeled.csv] (Эталонные данные)
         |
+--------+-------------------------------------------------------------+
|                                                                      |
v                                                                      v
+--------------------------------+        +-------------------------------------------------+
| ЧАСТЬ 3: create_image_dataset.py|        | ЧАСТЬ 4: Автоматизация анализа                  |
|          upload_dataset.py     |        |                                                 |
| (Создание и выгрузка датасета  |        |  (Два подхода)                                  |
| изображений на Hugging Face)   |        |                                                 |
+--------------------------------+        | а) find_patterns.py (по аудио/тексту)           |
         |                                | б) auto_classifier.py (по изображениям)         |
         v                                +-------------------------------------------------+
[Датасет на Hugging Face]                                              |
                                                                       v
                                                               [Автоматический отчет]```

### Структура проекта

```
.
├── films/                # Папка для исходных видеофайлов
├── part_films/           # Сюда сохраняются 10-минутные части видео
├── processed_data/       # Результаты обработки (кадры, аудио, признаки)
├── dataset_foto/         # Локальная папка для датасета изображений перед загрузкой
├── new_videos/           # Папка для видео для анализа моделью из Части 4а
├── auto_labeled_dataset/ # Результат работы модели из Части 4б
|
├── prepare_data.py       # [Часть 1] Основной скрипт подготовки данных
├── create_image_dataset.py # [Часть 3] Скрипт сборки датасета изображений
├── upload_dataset.py     # [Часть 3] Скрипт загрузки датасета на Hugging Face
├── find_patterns.py      # [Часть 4а] Скрипт для поиска паттернов по аудио/тексту
├── auto_classifier.py    # [Часть 4б] Скрипт для обучения и применения CV-модели
|
├── labeled.csv           # [Часть 2] Пример выгрузки из Label Studio
├── .env                  # Файл для хранения токена Hugging Face
├── requirements.txt      # Зависимости проекта
└── README.md             # Этот файл
```

### Пошаговый рабочий процесс

#### Часть 1. Подготовка данных

1.  Поместите ваш исходный `.mp4` файл в папку `films/`.
2.  Запустите скрипт:
    ```bash
    python prepare_data.py
    ```
3.  Скрипт быстро нарежет видео на 10-минутные части в `part_films/`, предложит выбрать одну для анализа и обработает ее, сохранив результаты в `processed_data/` и создав `tasks.json`.

#### Часть 2. Разметка в Label Studio

1.  Настройте проект в Label Studio.
2.  Подключите папку `processed_data/` как хранилище.
3.  Импортируйте `tasks.json`.
4.  Выполните разметку, используя настроенный интерфейс.
5.  Экспортируйте результаты разметки в формате CSV и сохраните как `labeled.csv` в корне проекта.

#### Часть 3. Создание и публикация датасета

1.  Убедитесь, что у вас есть `labeled.csv` и `processed_data/`.
2.  Создайте датасет локально:
    ```bash
    python create_image_dataset.py
    ```
3.  Создайте файл `.env` с вашим токеном Hugging Face.
4.  Загрузите датасет на Hugging Face Hub:
    ```bash
    python upload_dataset.py
    ```
    *Этот скрипт автоматически удалит старую версию датасета на Hub, добавит столбец с текстовыми метками и сгенерирует `README.md` для датасета.*

#### Часть 4. Автоматизация анализа

В проекте реализовано два независимых подхода к автоматизации:

*   **Анализ по аудио/текстовым признакам:** Используйте скрипт `find_patterns.py`. Этот подход легковесный и быстрый.
*   **Анализ по изображениям (ключевым кадрам):** Используйте скрипт `auto_classifier.py`. Этот подход требует обучения нейросети, но способен находить визуальные паттерны, недоступные первому методу. **(См. `readme_auto_class.md` для подробностей)**.

---

### 2. `readme_auto_class.md` (Отдельный README для автоматизации разметки)

# Автоматическая разметка видеокадров с помощью нейросети

Этот документ описывает процесс обучения и применения модели компьютерного зрения для автоматического определения педагогических паттернов в ключевых кадрах видео. Это **Часть 4б** основного проекта.

**Цель.** Создать систему, которая на основе небольшого, размеченного вручную набора изображений, сможет автоматически размечать большие объемы новых видеоматериалов.

### Архитектура решения

```
+--------------------------------+       +------------------------------------+
|   labeled.csv (ручная разметка)|       |   processed_data/ (ключевые кадры) |
+--------------------------------+       +------------------------------------+
                 |                                      |
                 +-----------------+--------------------+
                                   |
                                   v
+-----------------------------------------------------------------------------+
|                            Фаза 1: Обучение модели                          |
|                             (auto_classifier.py --mode train)               |
|                                                                             |
|   1. Загрузка данных и меток из labeled.csv.                                |
|   2. Обучение модели (transfer learning на базе MobileNetV2) для            |
|      multi-label классификации изображений.                                 |
+-----------------------------------------------------------------------------+
                                   |
                                   v
                      +-----------------------------+
                      |  image_pattern_model.h5     | (Обученная нейросеть)
                      +-----------------------------+
                                   |
+----------------------------------+------------------------------------------+
|                                  |
v                                  v
+-----------------------------+  +-------------------------------------+
| part_films/*.mp4            |  | image_pattern_model.h5 (Модель)     |
| (Новые, неразмеченные видео)|  +-------------------------------------+
+-----------------------------+    |
                                   v
+-----------------------------------------------------------------------------+
|                       Фаза 2: Автоматическая разметка                       |
|                           (auto_classifier.py --mode predict)               |
|                                                                             |
|   1. Извлечение ключевых кадров из выбранного видео.                        |
|   2. Предсказание ТОП-3 паттернов и их вероятностей для каждого кадра.      |
|   3. Формирование нового датасета `auto_labeled_dataset/` с изображениями   |
|      и файлом `metadata.jsonl`.                                             |
+-----------------------------------------------------------------------------+
```

### Пошаговая инструкция

#### Шаг 1. Установка зависимостей

Убедитесь, что у вас активно виртуальное окружение, и установите библиотеки для глубокого обучения:
```bash
pip install tensorflow scikit-learn pandas pillow opencv-python moviepy
```

#### Шаг 2. Обучение модели

**Пререквизиты:**
*   Файл `labeled.csv`, полученный после разметки в Label Studio.
*   Папка `processed_data/` с соответствующими ключевыми кадрами.

Запустите скрипт в режиме **обучения**:
```bash
python auto_classifier.py --mode train
```
Этот процесс проанализирует ваши размеченные данные, обучит нейросеть и сохранит в корне проекта два файла:
*   `image_pattern_model.h5`: Веса обученной нейросети.
*   `mlb.pkl`: Вспомогательный файл (`MultiLabelBinarizer`) для преобразования названий паттернов в векторы и обратно.

#### Шаг 3. Автоматическая разметка нового видео

Теперь, когда модель обучена, примените ее для анализа любого видеофрагмента.

Запустите скрипт в режиме **предсказания**:
```bash
python auto_classifier.py --mode predict
```1.  Скрипт покажет вам список доступных видеофайлов из папки `part_films/`.
2.  Введите номер видео, которое вы хотите разметить.
3.  Скрипт последовательно извлечет ключевые кадры из видео, для каждого получит предсказания от нейросети и сформирует итоговый датасет.

#### Шаг 4. Анализ результата

После выполнения в корне проекта появится папка `auto_labeled_dataset/` со следующей структурой:
```
auto_labeled_dataset/
├── images/
│   ├── segment_0_keyframe.jpg
│   └── ...
└── metadata.jsonl
```

Файл `metadata.jsonl` будет содержать детальную информацию о предсказаниях. Для каждого кадра будут указаны **три наиболее вероятных паттерна** и их **уверенность (confidence)**:
```json
{"file_name": "segment_0_keyframe.jpg", "top_3_predictions": [{"pattern": "Паттерн 1: Удержание внимания", "confidence": 0.89}, {"pattern": "Паттерн 7: Демонстрация примера", "confidence": 0.65}, {"pattern": "Паттерн 3: Вовлечение в диалог", "confidence": 0.41}]}
{"file_name": "segment_5_keyframe.jpg", "top_3_predictions": [{"pattern": "Паттерн 9: Рефлексия", "confidence": 0.95}, {"pattern": "Паттерн 2: Обратная связь", "confidence": 0.72}, {"pattern": "Паттерн 6: Работа с ошибками", "confidence": 0.33}]}
```
Этот автоматически сгенерированный датасет можно далее анализировать, загрузить на Hugging Face или использовать для дообучения модели (цикл активного обучения).

