# Датасет педагогических паттернов
Проект подготовки и анализа видеоданных для педагогики. Этот проект представляет собой полный цикл работы с видеоматериалами: от автоматической подготовки данных для разметки до создания и применения моделей машинного обучения, а также формирования эталонных датасетов изображений.

**Цикл проекта:**
1.  **Часть 1. Подготовка данных.** Быстрая нарезка видео и извлечение признаков для платформы Label Studio.
2.  **Часть 2. Разметка в Label Studio.** Процесс экспертной оценки 5-секундных сегментов.
3.  **Часть 3. ML-модель для признаков.** Обучение модели для автоматического поиска паттернов по аудио и текстовым признакам.
4.  **Часть 4. Формирование фото-датасета.** Создание структурированного датасета изображений с файлом метаданных `metadata.jsonl`, готового для загрузки на Hugging Face.

---

### Архитектура проекта

```
[Исходное видео]
     |
     v
+-----------------------------+
|    Часть 1: prepare_data.py | ---> [part_films/], [processed_data/]
| (Нарезка и извлечение)      |
+-----------------------------+
     |
     v
+-----------------------------+
|    Часть 2: Label Studio    | ---> [labeled.csv] (Результат разметки)
| (Экспертная разметка)       |
+-----------------------------+
     |                      |
     |                      v
     |      +------------------------------------------+
     |      |        Часть 4: create_image_dataset.py  |
     |      | (Формирование датасета с metadata.jsonl) |
     |      +------------------------------------------+
     |                      |
     |                      v
     |      [dataset_foto/] (images/ + metadata.jsonl)
     |
     v
+-----------------------------+
| Часть 3: find_patterns.py   | ---> [Отчет о паттернах]
| (Применение ML-модели)      |
+-----------------------------+
```
---
*(Разделы 1, 2 и 3 остаются без изменений, переходим сразу к новой, переработанной Части 4)*

## Часть 4. Формирование датасета изображений для Hugging Face (с `metadata.jsonl`)

Эта часть проекта автоматизирует создание структурированного датасета изображений. Вместо создания подпапок для каждого класса (что неудобно для multi-label задач), мы сформируем единую папку с изображениями и файл с метаданными `metadata.jsonl`, который связывает каждый файл с его паттернами. Это стандартный и рекомендуемый формат для Hugging Face.

### Алгоритм формирования датасета

1.  **Входные данные**:
    *   `labeled.csv`: Файл с результатами разметки.
    *   `processed_data/`: Папка с ключевыми кадрами.

2.  **Процесс**:
    *   Скрипт создает новую директорию `dataset_foto/`, а внутри нее — подпапку `images/`.
    *   Он читает `labeled.csv` и итерируется по строкам.
    *   Для каждой строки он находит соответствующий ключевой кадр в `processed_data/` и **один раз** копирует его в `dataset_foto/images/`.
    *   Параллельно для каждой строки формируется JSON-объект, содержащий имя файла и список его паттернов.
    *   Все эти JSON-объекты записываются в файл `dataset_foto/metadata.jsonl`, по одному на строку.

3.  **Выход**:
    *   Папка `dataset_foto/` со следующей структурой:
        ```
        dataset_foto/
        ├── images/
        │   ├── segment_0_keyframe.jpg
        │   ├── segment_5_keyframe.jpg
        │   └── ...
        └── metadata.jsonl
        ```    *   Файл `metadata.jsonl` будет выглядеть так:
        ```json
        {"file_name": "segment_0_keyframe.jpg", "patterns": ["Паттерн 1: Удержание внимания", "Паттерн 9: Рефлексия"]}
        {"file_name": "segment_5_keyframe.jpg", "patterns": ["Паттерн 2: Обратная связь"]}
        ...
        ```


### Как запустить и загрузить на Hugging Face

**Шаг 1. Запуск скрипта**
Убедитесь, что у вас есть `labeled.csv` и папка `processed_data`, затем выполните:
```bash
python create_image_dataset.py
```

**Шаг 2. Загрузка на Hugging Face Hub**
Этот новый формат требует другого подхода к загрузке.

1.  **Установите библиотеки:**
    ```bash
    pip install datasets huggingface_hub Pillow
    ```

2.  **Авторизуйтесь:**
    ```bash
    huggingface-cli login
    ```

3.  **Создайте скрипт `upload_dataset.py`**
    

4.  **Запустите загрузку:**
    ```bash
    python upload_dataset.py

    ```


