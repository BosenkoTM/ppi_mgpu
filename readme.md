# **PPI Video Processing Platform**

**Pedagogical Pattern Infrastructure (PPI)** — это комплексная веб-платформа, предназначенная для анализа видеозаписей учебных процессов. Она позволяет исследователям и разработчикам проходить полный цикл от сырого видео до готового, структурированного датасета для обучения моделей машинного обучения.

**Цель проекта** — автоматизировать и упростить процесс выявления, разметки и анализа педагогических паттернов.

---

### **Общая схема работы**

Весь процесс построен на последовательном выполнении трех логических этапов, которые проводят пользователя от исходного видео до опубликованного датасета.

```mermaid
graph TD
    subgraph Этап 1. Подготовка
        A[Загрузка видео] --> B{Облачное хранилище MinIO};
    end

    subgraph Этап 2. Разметка датасета
        B --> C[2.1. Ручная разметка в Label Studio];
        C --> D[Получение JSON разметки];
        B & D --> E[2.2. Создание и фильтрация датасета];
    end

    subgraph Этап 3. Публикация
        E --> F[Готовый датасет];
        F --> G[3. Публикация в Hugging Face Hub];
    end

    style A fill:#e3f2fd,stroke:#333,stroke-width:2px
    style C fill:#e3f2fd,stroke:#333,stroke-width:2px
    style E fill:#fff9c4,stroke:#333,stroke-width:2px
    style G fill:#dcedc8,stroke:#333,stroke-width:2px
```

---

## **🚀 Рабочий процесс: от видео до датасета**

### **Этап 1. Загрузка видео в облачное хранилище**

**Цель:** Безопасно загрузить исходное видео в централизованное хранилище и подготовить его к разметке.

**Как это работает:**
1.  **Аутентификация.** Пользователь входит в систему под своей учетной записью (`admin` или `DL-user`).
2.  **Загрузка видео.** Через веб-интерфейс пользователь загружает видеофайл урока. Система автоматически извлекает из него аудиодорожку.
3.  **Хранение.** Видео и аудио сохраняются в облачное хранилище MinIO [настройка хранилища](docs/admin_minio.md) в изолированную папку, привязанную к пользователю или задаче.

**Результат этапа.** Видеофайл и его аудиодорожка находятся в облаке и готовы для следующего шага.

---

### **Этап 2. Разметка и формирование датасета**

**Цель.** Сначала вручную разметить видео, выделив педагогические паттерны, а затем на основе этой разметки автоматически сгенерировать структурированный, отфильтрованный и обогащенный мультимодальный датасет.

#### **2.1. Разметка видео в Label Studio**

[Label Studio](https://github.com/HumanSignal/label-studio?tab=readme-ov-file#citation)

**Процесс:**
*   Система предоставляет временную защищенную ссылку (presigned URL) на загруженное видео.
*   Пользователь импортирует видео по этой ссылке в **Label Studio** и, следуя **[руководству по разметке](docs/labelling_lstudio.md)**, аннотирует временные интервалы, соответствующие различным педагогическим паттернам.
*   Результат разметки выгружается в виде **JSON-файла**.

**Результат подэтапа.** JSON-файл с точными временными метками для каждого обнаруженного паттерна.

#### **2.2. Формирование и фильтрация датасета**

**Процесс:**
*   Это автоматизированный шаг, который выполняется с помощью набора Python-скриптов.
*   Скрипты принимают на вход **исходное видео**, полученный **JSON-файл разметки** и **Excel-файл с описанием паттернов**.
*   Процесс состоит из двух ключевых фаз:
    1.  **Извлечение артефактов:** Для каждой аннотации в JSON-файле скрипт автоматически вырезает видеофрагмент и извлекает из его середины ключевой кадр (фото).
    2.  **Сборка и обогащение:** Скрипт извлекает аудиодорожку из каждого видеофрагмента, транскрибирует речь с помощью Whisper, а затем связывает все медиафайлы с описаниями из Excel.
    3.  **Интерактивная фильтрация:** Перед финальной сборкой система предлагает пользователю просмотреть список всех извлеченных кадров и ввести номера тех, которые нужно исключить (например, если в кадр не попал преподаватель). Это гарантирует высокое качество итогового датасета.

**Архитектура обработки:**

```mermaid
graph TD
    subgraph "Входные данные"
        A["Видео .mp4"]
        B["Разметка .json"]
        C["Описания .xlsx"]
    end

    subgraph "Шаг 1: main"
        D["Извлечение ключевых кадров"]
    end

    subgraph "Шаг 2: prepare_dataset"
        F["аудио и транскрибация"]
        G{"Интерактивная фильтрация"}
        H["Сборка метаданных CSV"]
    end
    
    subgraph "Выход"
        I["huggingface dataset"]
    end

    A & B --> D
    D --> F
    C --> H
    F --> G
    G -- "Отфильтрованные данные" --> H
    H --> I

    style G fill:#f8bbd0,stroke:#c2185b,stroke-width:2px,stroke-dasharray: 5 5
```

**Результат этапа.** Готовая к публикации папка, содержащая подпапки с отфильтрованными изображениями, видеоклипами, аудиофайлами, текстами и главным `metadata.csv` файлом, который все это связывает.

---

### **Этап 3. Публикация датасета в Hugging Face**

**Цель.** Сделать готовый, качественный датасет доступным для всего мира или для исследовательской группы, опубликовав его на платформе Hugging Face.

**Как это работает:**
1.  **Аутентификация.** Запускается скрипт, который запрашивает токен доступа к Hugging Face.
2.  **Подготовка к публикации.** Автоматически создается карточка датасета (README) с описанием его структуры, примеров использования и назначения.
3.  **Загрузка в Hub.** Вся структура папок, полученная на Этапе 2, загружается в новый репозиторий на Hugging Face Hub.
4.  **Публикация.** Датасет становится доступен по ссылке и может быть легко интегрирован в ML-пайплайны.

**Архитектура загрузки:**

```mermaid
graph TD
    subgraph "Входные данные"
        A["Папка huggingface_dataset"]
        B["Hugging Face Token"]
    end
    
    subgraph "Процесс загрузки (upload_to_hf.py)"
        C["Аутентификация в HF Hub"] --> D["Создание Dataset Card (README.md)"]
        D --> E["Загрузка файлов и метаданных"]
    end
    
    subgraph "Результат"
        F["датасет на Hugging Face Hub"]
    end
    
    A & B --> C
    E --> F
```

**Пример готового датасета:**
*   [ppi](https://huggingface.co/datasets/icomgpu/ppi)

---

## **🛠️ Техническая документация для разработчиков**

<details>
<summary><b>🏗️ Архитектура, локальный пайплайн, установка и авторизация...</b></summary>

### **Локальный скриптовый пайплайн обработки**

В качестве альтернативы веб-платформе, весь процесс может быть выполнен локально с помощью набора Python-скриптов.

#### **Архитектура решения**

```
┌─────────────────────────────────────────────────────────────────┐
│                         Входные данные                          │
│  ┌──────────┐  ┌──────────┐  ┌──────────────┐                   │
│  │   .mp4   │  │ .json  │  │patterns.xlsx │                   │
│  │ (видео)  │  │ (аннот.) │  │ (описание)   │                   │
│  └──────────┘  └──────────┘  └──────────────┘                   │
└─────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│                    Модуль 1: main.py                            │
│              Обработка видео и извлечение сегментов             │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ 1. Парсинг JSON-аннотаций из Label Studio                │   │
│  │ 2. Создание обрезанных видео-сегментов по временным      │   │
│  │    меткам (start_time, end_time)                         │   │
│  │ 3. Извлечение ключевого кадра:                           │   │
│  │    mid_time = (start_time + end_time) / 2                │   │
│  │    frame = video.get_frame(mid_time)                     │   │
│  │ 4. Применение обрезки по координатам (если указаны)      │   │
│  └──────────────────────────────────────────────────────────┘   │
│  Выход: dataset_cropped/ (видео + изображения)                  │
└─────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│                 Модуль 2: prepare_dataset.py                    │
│              Подготовка датасета с транскрипцией                │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ 1. Копирование видео и изображений                       │   │
│  │ 2. Извлечение аудиодорожек (WAV, 16kHz, моно)            │   │
│  │ 3. Транскрибация аудио (Whisper/faster-whisper)          │   │
│  │    - Автоматическое определение языка (en/ru)            │   │
│  │ 4. Создание metadata.csv                                 │   │
│  │ 5. Интерактивное удаление некачественных кадров          │   │
│  └──────────────────────────────────────────────────────────┘   │
│  Выход: huggingface_dataset/ (полный датасет)                   │
└─────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│                  Модуль 3: upload_to_hf.py                      │
│              Загрузка датасета на Hugging Face Hub              │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ 1. Аутентификация в Hugging Face Hub                     │   │
│  │ 2. Создание Dataset Card (README.md)                     │   │
│  │ 3. Формирование Dataset из файлов и метаданных           │   │
│  │ 4. Загрузка на Hugging Face Hub                          │   │
│  └──────────────────────────────────────────────────────────┘   │
│  Выход: Публикация на Hugging Face Hub                          │
└─────────────────────────────────────────────────────────────────┘
```





---
*(... остальная часть технической документации из исходного файла ...)*

</details>

---

## **👥 Материалы и ссылки**

-   **GitHub:** [Описание проекта](https://bosenkotm.github.io/ppi_mgpu/)
-   **Hugging Face:** [Пример датасета](https://huggingface.co/datasets/icomgpu/ppi)
-   **Документация по процессам:**
    -   [Установка и настройка хранилища MinIO](docs/admin_minio.md)
    -   [Руководство по разметке в Label Studio](docs/labelling_lstudio.md)
    -   [Процесс формирования датасета (Benchmark)](docs/benchmarks_creating.md)









